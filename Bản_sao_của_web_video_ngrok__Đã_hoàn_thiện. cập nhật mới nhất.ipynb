{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/congnhatdt03-hue/Nhan_dien_bien_so_xe/blob/main/B%E1%BA%A3n_sao_c%E1%BB%A7a_web_video_ngrok__%C4%90%C3%A3_ho%C3%A0n_thi%E1%BB%87n.%20c%E1%BA%ADp%20nh%E1%BA%ADt%20m%E1%BB%9Bi%20nh%E1%BA%A5t.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "veAin55AL1i-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63272a79-c361-47af-81f7-fece6321503d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m963.8/963.8 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for cloudflared (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit opencv-python pillow ultralytics easyocr google-generativeai cloudflared\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rVKuQEIMNLo",
        "outputId": "df2f9515-094d-46f7-c85d-7be36f22fdef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mjMuKVhXMSvf"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/project/models\n",
        "!cp \"/content/drive/MyDrive/ƒë·ªì √°n 2/best.pt\" /content/project/models/\n",
        "!cp \"/content/drive/MyDrive/ƒëoÃÇÃÄ aÃÅn 2/sort.py\" /content/project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP-qu_xYqGhZ",
        "outputId": "f9453d36-93bd-4a1e-ba79-3c4d009378d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/178.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from filterpy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from filterpy) (1.16.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from filterpy) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.17.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110460 sha256=1b44ed2a19319039df73cf1b6642eed549b9150bd4058d2f3a95635bb5011a10\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/bf/4c/b0c3f4798a0166668752312a67118b27a3cd341e13ac0ae6ee\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy\n",
            "Successfully installed filterpy-1.4.5\n"
          ]
        }
      ],
      "source": [
        "!pip install filterpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft1rNC3Le6tE",
        "outputId": "cfc4e7c6-1c68-4b5d-af76-ba4c4227debd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/project/app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/project/app.py\n",
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import tempfile\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "import easyocr\n",
        "from collections import Counter\n",
        "import sys\n",
        "sys.path.append('/content/sort')  # Th√™m n·∫øu ch∆∞a c√≥\n",
        "from sort import Sort\n",
        "import subprocess\n",
        "\n",
        "st.set_page_config(page_title=\"Nh·∫≠n di·ªán bi·ªÉn s·ªë xe\", layout=\"wide\")\n",
        "# =================== H√ÄM H·ªñ TR·ª¢ ===================\n",
        "def iou(b1, b2):\n",
        "    x1, y1, x2, y2 = b1\n",
        "    X1, Y1, X2, Y2 = b2\n",
        "    inter_x1, inter_y1 = max(x1, X1), max(y1, Y1)\n",
        "    inter_x2, inter_y2 = min(x2, X2), min(y2, Y2)\n",
        "    iw, ih = max(0, inter_x2 - inter_x1), max(0, inter_y2 - inter_y1)\n",
        "    inter = iw * ih\n",
        "    a1 = (x2 - x1) * (y2 - y1)\n",
        "    a2 = (X2 - X1) * (Y2 - Y1)\n",
        "    return inter / (a1 + a2 - inter + 1e-6)\n",
        "\n",
        "def sharpness_score(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "\n",
        "# ====== CONFIG ======\n",
        "YOLO_PATH = \"/content/drive/MyDrive/ƒëoÃÇÃÄ aÃÅn 2/best.pt\"\n",
        "FRAME_STEP = 200  # ms, gi·∫£m OCR ƒë·ªÉ m∆∞·ª£t h∆°n\n",
        "CONFIDENCE_THRESHOLD = 0.25\n",
        "USE_EASYOCR_FALLBACK = True\n",
        "IOU_TH = 0.6      # Match ch·∫Øc h∆°n\n",
        "MAX_AGE = 50      # Track gi·ªØ l√¢u h∆°n\n",
        "\n",
        "# ====== GEMINI API KEY ======\n",
        "import google.generativeai as genai\n",
        "GEMINI_API_KEY = st.sidebar.text_input(\"üîë Nh·∫≠p Gemini API Key:\", type=\"password\")\n",
        "if GEMINI_API_KEY:\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "else:\n",
        "    gemini_model = None\n",
        "\n",
        "# ====== LOAD YOLO MODEL ======\n",
        "@st.cache_resource\n",
        "def load_yolo(path):\n",
        "    model = YOLO(path)\n",
        "    return model\n",
        "model = load_yolo(YOLO_PATH)\n",
        "\n",
        "# ====== REGEX CHU·∫®N H√ìA ======\n",
        "FALLBACK_REGEX = re.compile(r\"(\\d{2})\\s*[- ]?\\s*([A-Z]{1,2})\\s*[- ]?\\s*([0-9]{2,6})\")\n",
        "def normalize_plate(text: str) -> str:\n",
        "    text = text.upper()\n",
        "    text = re.sub(r\"[^A-Z0-9]\", \"\", text)\n",
        "    match = re.match(r\"^(\\d{2})([A-Z]{1,2})(\\d{2,6})$\", text)\n",
        "    if match:\n",
        "        p1, p2, p3 = match.groups()\n",
        "        return f\"{p1}-{p2} {p3}\"\n",
        "    match2 = FALLBACK_REGEX.search(text)\n",
        "    if match2:\n",
        "        p1, p2, p3 = match2.groups()\n",
        "        return f\"{p1}-{p2} {p3}\"\n",
        "    return text\n",
        "\n",
        "# ====== OCR ======\n",
        "def ocr_with_gemini(image: Image.Image) -> str:\n",
        "    try:\n",
        "        prompt = \"ƒê·ªçc bi·ªÉn s·ªë xe trong ·∫£nh (ch·ªâ tr·∫£ l·ªùi bi·ªÉn s·ªë, kh√¥ng th√™m k√Ω t·ª± n√†o kh√°c):\"\n",
        "        res = gemini_model.generate_content([prompt, image])\n",
        "        txt = res.text.strip()\n",
        "        return normalize_plate(txt)\n",
        "    except Exception as e:\n",
        "        st.warning(f\"L·ªói Gemini: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "@st.cache_resource\n",
        "def load_easyocr():\n",
        "    return easyocr.Reader(['en'])\n",
        "\n",
        "def ocr_with_easyocr(image: np.ndarray) -> str:\n",
        "    reader = load_easyocr()\n",
        "    results = reader.readtext(image)\n",
        "    txt = \" \".join([r[1] for r in results])\n",
        "    return normalize_plate(txt)\n",
        "\n",
        "# ====== TI·ªÄN X·ª¨ L√ù ROI ======\n",
        "def enhance_roi(roi: np.ndarray) -> np.ndarray:\n",
        "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(gray)\n",
        "    sharp = cv2.addWeighted(clahe, 1.5, cv2.GaussianBlur(clahe, (0,0), 1), -0.5, 0)\n",
        "    return cv2.cvtColor(sharp, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# ====== HI·ªÇN TH·ªä GIAO DI·ªÜN ======\n",
        "st.title(\"Nh·∫≠n di·ªán bi·ªÉn s·ªë xe t·ª´ ·∫£nh ho·∫∑c video\")\n",
        "st.markdown(\"<div style='text-align:center; font-size:18px; color:gray;'>ƒê·ªì √°n II ‚Äì GVHD: ThS. Nguy·ªÖn Th·ªã Hu·∫ø</div>\", unsafe_allow_html=True)\n",
        "\n",
        "input_type = st.radio(\"Ch·ªçn lo·∫°i d·ªØ li·ªáu:\", [\"·∫¢nh\", \"Video\"])\n",
        "\n",
        "if input_type == \"·∫¢nh\":\n",
        "    uploaded_file = st.file_uploader(\"üì§ T·∫£i l√™n ·∫£nh\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "else:\n",
        "    uploaded_file = st.file_uploader(\"üì§ T·∫£i l√™n video\", type=[\"mp4\", \"mov\", \"avi\"])\n",
        "\n",
        "if uploaded_file and st.button(\"üöÄ B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán\"):\n",
        "    plate_counter = Counter()\n",
        "\n",
        "    # ====== X·ª¨ L√ù ·∫¢NH ======\n",
        "    if input_type == \"·∫¢nh\":\n",
        "        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
        "        image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
        "        result = model.predict(image, conf=CONFIDENCE_THRESHOLD)[0]\n",
        "        annotated = image.copy()\n",
        "\n",
        "        if len(result.boxes) == 0:\n",
        "            st.warning(\"‚ùå Kh√¥ng c√≥ bi·ªÉn s·ªë ƒë∆∞·ª£c ph√°t hi·ªán.\")\n",
        "        else:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                roi = annotated[y1:y2, x1:x2]\n",
        "                roi = enhance_roi(roi)\n",
        "\n",
        "                if gemini_model:\n",
        "                    pil_roi = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
        "                    text = ocr_with_gemini(pil_roi)\n",
        "                    if not text.strip():\n",
        "                        st.info(\"‚ö†Ô∏è Gemini v∆∞·ª£t quota ‚Üí d√πng EasyOCR.\")\n",
        "                        text = ocr_with_easyocr(roi)\n",
        "                else:\n",
        "                    text = ocr_with_easyocr(roi) if USE_EASYOCR_FALLBACK else \"\"\n",
        "\n",
        "                plate_counter[text] += 1\n",
        "                cv2.rectangle(annotated, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "                cv2.putText(annotated, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
        "\n",
        "            st.image(annotated, caption=\"·∫¢nh ƒë√£ nh·∫≠n di·ªán\", channels=\"BGR\", use_column_width=True)\n",
        "\n",
        "    # ====== X·ª¨ L√ù VIDEO ======\n",
        "    else:\n",
        "        # L∆∞u file t·∫°m\n",
        "        temp_video = tempfile.NamedTemporaryFile(delete=False)\n",
        "        temp_video.write(uploaded_file.read())\n",
        "        temp_video_path = temp_video.name\n",
        "\n",
        "        cap = cv2.VideoCapture(temp_video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        frame_interval = int(fps * FRAME_STEP / 1000) if FRAME_STEP > 0 else 1\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        out_path = \"output_annotated.mp4\"\n",
        "        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
        "\n",
        "        frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        pbar = st.progress(0.0)\n",
        "        ocr_status = st.empty()\n",
        "\n",
        "        # ================= PASS 1: Qu√©t video, t·∫°o track v·ªõi SORT, ch·ªçn ROI s·∫Øc n√©t nh·∫•t =================\n",
        "        sort_tracker = Sort(max_age=MAX_AGE, min_hits=1, iou_threshold=IOU_TH)\n",
        "        tracks = {}  # tid -> {\"best_roi\": np.array, \"best_score\": float, \"text\": str, \"boxes_history\": list}\n",
        "        box_found = False\n",
        "        idx = 0\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if idx % frame_interval == 0:\n",
        "                result = model.predict(frame, conf=CONFIDENCE_THRESHOLD)[0]\n",
        "                dets = np.array([[*box.xyxy[0].cpu().numpy(), box.conf[0].cpu().numpy()] for box in result.boxes]) if len(result.boxes) > 0 else np.empty((0, 5))\n",
        "                if len(dets) > 0:\n",
        "                    box_found = True\n",
        "            else:\n",
        "                dets = np.empty((0, 5))\n",
        "\n",
        "            trackers = sort_tracker.update(dets)\n",
        "\n",
        "            for track in trackers:\n",
        "                x1, y1, x2, y2, tid = map(int, track)\n",
        "                if tid not in tracks:\n",
        "                    tracks[tid] = {\n",
        "                        \"best_roi\": None,\n",
        "                        \"best_score\": -1.0,\n",
        "                        \"text\": \"\",\n",
        "                        \"boxes_history\": []\n",
        "                    }\n",
        "\n",
        "                # L∆∞u l·ªãch s·ª≠ box ƒë·ªÉ l√†m m∆∞·ª£t\n",
        "                tracks[tid][\"boxes_history\"].append([x1, y1, x2, y2])\n",
        "                if len(tracks[tid][\"boxes_history\"]) > 7:  # Gi·ªØ 7 frame\n",
        "                    tracks[tid][\"boxes_history\"].pop(0)\n",
        "\n",
        "                # C·∫≠p nh·∫≠t ROI s·∫Øc n√©t nh·∫•t\n",
        "                matched = any(iou([x1, y1, x2, y2], det[:4]) > IOU_TH for det in dets)\n",
        "                if matched:\n",
        "                    roi_x1, roi_y1, roi_x2, roi_y2 = map(int, [x1, y1, x2, y2])\n",
        "                    roi = frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
        "                    if roi.size == 0:\n",
        "                        continue\n",
        "                    roi = enhance_roi(roi)\n",
        "                    sc = sharpness_score(roi)\n",
        "                    if sc > tracks[tid][\"best_score\"]:\n",
        "                        tracks[tid][\"best_score\"] = sc\n",
        "                        tracks[tid][\"best_roi\"] = roi\n",
        "\n",
        "            idx += 1\n",
        "            pbar.progress(min(idx / max(frames, 1), 1.0))\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        # ================= OCR m·ªôt l·∫ßn duy nh·∫•t cho m·ªói track =================\n",
        "        unique_texts = []\n",
        "        for tid, t in tracks.items():\n",
        "            if t[\"best_roi\"] is not None:\n",
        "                try:\n",
        "                    if gemini_model:\n",
        "                        ocr_status.markdown(\"‚úÖ **ƒêang d√πng Gemini OCR**\", unsafe_allow_html=True)\n",
        "                        pil_roi = Image.fromarray(cv2.cvtColor(t[\"best_roi\"], cv2.COLOR_BGR2RGB))\n",
        "                        txt = ocr_with_gemini(pil_roi)\n",
        "                        if not txt.strip():\n",
        "                            ocr_status.markdown(\"‚ö†Ô∏è **Gemini v∆∞·ª£t quota, chuy·ªÉn EasyOCR**\", unsafe_allow_html=True)\n",
        "                            txt = ocr_with_easyocr(t[\"best_roi\"])\n",
        "                    else:\n",
        "                        ocr_status.markdown(\"‚ö†Ô∏è **Ch∆∞a c√≥ API key, d√πng EasyOCR**\", unsafe_allow_html=True)\n",
        "                        txt = ocr_with_easyocr(t[\"best_roi\"])\n",
        "                    t[\"text\"] = txt.strip()\n",
        "                except Exception as e:\n",
        "                    ocr_status.markdown(f\"‚ö†Ô∏è **Gemini l·ªói ({e}), d√πng EasyOCR**\", unsafe_allow_html=True)\n",
        "                    t[\"text\"] = ocr_with_easyocr(t[\"best_roi\"])\n",
        "                if t[\"text\"]:\n",
        "                    unique_texts.append(t[\"text\"])\n",
        "\n",
        "        # ================= PASS 2: Ghi video output v·ªõi nh√£n c·ªë ƒë·ªãnh, smooth box =================\n",
        "        cap = cv2.VideoCapture(temp_video_path)\n",
        "        sort_tracker = Sort(max_age=MAX_AGE, min_hits=1, iou_threshold=IOU_TH)\n",
        "        idx = 0\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if idx % frame_interval == 0:\n",
        "                result = model.predict(frame, conf=CONFIDENCE_THRESHOLD)[0]\n",
        "                dets = np.array([[*box.xyxy[0].cpu().numpy(), box.conf[0].cpu().numpy()] for box in result.boxes]) if len(result.boxes) > 0 else np.empty((0, 5))\n",
        "            else:\n",
        "                dets = np.empty((0, 5))\n",
        "\n",
        "            trackers = sort_tracker.update(dets)\n",
        "\n",
        "            for track in trackers:\n",
        "                x1, y1, x2, y2, tid = map(int, track)\n",
        "                # Match tid v·ªõi tracks t·ª´ pass 1 b·∫±ng IoU\n",
        "                best_tid, best_iou = None, 0.0\n",
        "                for saved_tid, t in tracks.items():\n",
        "                    if t[\"boxes_history\"]:\n",
        "                        boxes_np = np.array(t[\"boxes_history\"])\n",
        "                        last_box = np.mean(boxes_np, axis=0).astype(int)  # Moving average\n",
        "                        ov = iou([x1, y1, x2, y2], last_box)\n",
        "                        if ov > IOU_TH and ov > best_iou:\n",
        "                            best_tid, best_iou = saved_tid, ov\n",
        "\n",
        "                if best_tid is not None:\n",
        "                    label = tracks[best_tid][\"text\"]\n",
        "                    # L√†m m∆∞·ª£t box b·∫±ng moving average\n",
        "                    if tracks[best_tid][\"boxes_history\"]:\n",
        "                        boxes_np = np.array(tracks[best_tid][\"boxes_history\"])\n",
        "                        x1, y1, x2, y2 = np.mean(boxes_np, axis=0).astype(int)\n",
        "                else:\n",
        "                    label = \"\"\n",
        "\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                if label:\n",
        "                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "            out.write(frame)\n",
        "            idx += 1\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        # ================= Hi·ªÉn th·ªã k·∫øt qu·∫£ =================\n",
        "        if not box_found:\n",
        "            st.warning(\"‚ùå Kh√¥ng c√≥ bi·ªÉn s·ªë ƒë∆∞·ª£c ph√°t hi·ªán trong video.\")\n",
        "        else:\n",
        "            # 1) Hi·ªÉn th·ªã video g·ªëc (CƒÉn gi·ªØa & thu nh·ªè)\n",
        "            st.subheader(\" Video t·∫£i l√™n\")\n",
        "            col1, col2, col3 = st.columns([1, 2, 1])  # 2 c·ªôt tr·ªëng ƒë·ªÉ cƒÉn gi·ªØa video\n",
        "            with col2:\n",
        "                st.video(temp_video_path)\n",
        "            # 2) Hi·ªÉn th·ªã ·∫£nh ROI t·ªët nh·∫•t c·ªßa t·ª´ng bi·ªÉn s·ªë (n·∫øu c√≥)\n",
        "            for tid, t in tracks.items():\n",
        "                if t[\"best_roi\"] is not None and t[\"text\"]:\n",
        "                    st.image(\n",
        "                        t[\"best_roi\"],\n",
        "                        caption=f\"üñºÔ∏è Track #{tid} (Bi·ªÉn s·ªë: {t['text']})\",\n",
        "                        use_column_width=True\n",
        "                    )\n",
        "\n",
        "            # 3) N√∫t t·∫£i video k·∫øt qu·∫£ c√≥ bbox & bi·ªÉn s·ªë\n",
        "            st.subheader(\"üì• Video ƒë√£ nh·∫≠n di·ªán\")\n",
        "            with open(out_path, \"rb\") as f:\n",
        "                st.download_button(\n",
        "                    \"üì• T·∫£i video ƒë√£ nh·∫≠n di·ªán\",\n",
        "                    f,\n",
        "                    file_name=\"output_annotated.mp4\"\n",
        "                )\n",
        "\n",
        "        # C·∫≠p nh·∫≠t danh s√°ch bi·ªÉn s·ªë ƒë√£ nh·∫≠n di·ªán\n",
        "        for txt in unique_texts:\n",
        "            plate_counter[txt] += 1\n",
        "\n",
        "    # ===== K·∫æT QU·∫¢ CU·ªêI =====\n",
        "    st.subheader(\"üìã Bi·ªÉn s·ªë ph√°t hi·ªán ƒë∆∞·ª£c:\")\n",
        "    found_plate = False\n",
        "    for plate, count in plate_counter.items():\n",
        "        if plate.strip():\n",
        "            st.write(f\"- **{plate}** ({count} l·∫ßn)\")\n",
        "            found_plate = True\n",
        "    if not found_plate:\n",
        "        st.warning(\"‚ùå Kh√¥ng c√≥ bi·ªÉn s·ªë ƒë∆∞·ª£c ph√°t hi·ªán.\")\n",
        "\n",
        "# ===== GHI CH√ö =====\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "        <div style='position: fixed; bottom: 10px; right: 10px; font-size: 14px; color: gray;'>\n",
        "           By V√µ C√¥ng Nh·∫≠t-20222627.\n",
        "        </div>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "# D·ªçn file t·∫°m\n",
        "if 'temp_video' in locals() and os.path.exists(temp_video.name):\n",
        "    os.unlink(temp_video.name)\n",
        "if 'out_path' in locals() and os.path.exists(out_path):\n",
        "    os.unlink(out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BBfmOYa5MpU3"
      },
      "outputs": [],
      "source": [
        "!streamlit run /content/project/app.py --server.port 8501 &> /content/log.txt &\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYHvpUgjMrkH",
        "outputId": "91280d14-ee46-4117-eff4-269db814354f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-08-25T03:56:24Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-08-25T03:56:24Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m |  https://replica-acne-doctor-likewise.trycloudflare.com                                    |\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.8.1 (Checksum a66353004197ee4c1fcb68549203824882bba62378ad4d00d234bdb8251f1114)\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: e1b2e648-f238-4780-888f-007ac8252f61\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "2025/08/25 03:56:27 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-08-25T03:56:27Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0mc89c86e6-243f-4c50-97bb-c67d3cfc0223 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7 \u001b[36mlocation=\u001b[0miad17 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-08-25T03:59:31Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared\n",
        "!./cloudflared tunnel --url http://localhost:8501\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGo1755rX5zpYtMzk/VkUJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}