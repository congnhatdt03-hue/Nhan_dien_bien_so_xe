{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/congnhatdt03-hue/Nhan_dien_bien_so_xe/blob/main/B%E1%BA%A3n_sao_c%E1%BB%A7a_web_video_ngrok__%C4%90%C3%A3_ho%C3%A0n_thi%E1%BB%87n_b%C3%A1o_c%C3%A1o_c%C3%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "veAin55AL1i-"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit opencv-python pillow ultralytics easyocr google-generativeai cloudflared\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rVKuQEIMNLo",
        "outputId": "25fe4117-2c4a-4902-b438-876fc2f9be45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mjMuKVhXMSvf"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/project/models\n",
        "!cp \"/content/drive/MyDrive/ƒë·ªì √°n 2/best.pt\" /content/project/models/\n",
        "!cp \"/content/drive/MyDrive/ƒëoÃÇÃÄ aÃÅn 2/sort.py\" /content/project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP-qu_xYqGhZ",
        "outputId": "b1e05b2e-31d7-45bf-e97f-13797ac04f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/178.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from filterpy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from filterpy) (1.16.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from filterpy) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.17.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110460 sha256=f11d58c6158b064d7832a88578a0592844ada48259657f84a85cf7e1233e99e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/bf/4c/b0c3f4798a0166668752312a67118b27a3cd341e13ac0ae6ee\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy\n",
            "Successfully installed filterpy-1.4.5\n"
          ]
        }
      ],
      "source": [
        "!pip install filterpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft1rNC3Le6tE",
        "outputId": "ea4bab69-a476-4eee-da63-9e0a58a98c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/project/app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/project/app.py\n",
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import tempfile\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "import easyocr\n",
        "from collections import Counter\n",
        "import sys\n",
        "sys.path.append('/content/sort')  # Th√™m n·∫øu ch∆∞a c√≥\n",
        "from sort import Sort\n",
        "import subprocess\n",
        "import torch  # Th√™m ƒë·ªÉ check GPU\n",
        "from difflib import SequenceMatcher  # Th√™m cho merge (n·∫øu d√πng similarity, nh∆∞ng ·ªü ƒë√¢y d√πng IoU)\n",
        "import pandas as pd  # Th√™m cho export CSV\n",
        "\n",
        "st.set_page_config(page_title=\"Nh·∫≠n di·ªán bi·ªÉn s·ªë xe\", layout=\"wide\")\n",
        "\n",
        "# =================== H√ÄM H·ªñ TR·ª¢ ===================\n",
        "def iou(b1, b2):\n",
        "    x1, y1, x2, y2 = b1\n",
        "    X1, Y1, X2, Y2 = b2\n",
        "    inter_x1, inter_y1 = max(x1, X1), max(y1, Y1)\n",
        "    inter_x2, inter_y2 = min(x2, X2), min(y2, Y2)\n",
        "    iw, ih = max(0, inter_x2 - inter_x1), max(0, inter_y2 - inter_y1)\n",
        "    inter = iw * ih\n",
        "    a1 = (x2 - x1) * (y2 - y1)\n",
        "    a2 = (X2 - X1) * (Y2 - Y1)\n",
        "    return inter / (a1 + a2 - inter + 1e-6)\n",
        "\n",
        "def sharpness_score(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "\n",
        "# ====== H√ÄM KI·ªÇM TRA BI·ªÇN S·ªê H·ª¢P L·ªÜ ======\n",
        "VALID_PLATE_REGEX = re.compile(r\"^(\\d{2}|T\\d{1,2})[- ]?([A-Z]{1,2})[- ]?(\\d{2,6})$\")\n",
        "VALID_PROVINCES = {\n",
        "    \"11\", \"12\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\",\n",
        "    \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\",\n",
        "    \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\",\n",
        "    \"40\", \"41\", \"43\", \"47\", \"49\", \"50\", \"51\", \"52\", \"53\",\n",
        "    \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\", \"61\", \"62\",\n",
        "    \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"72\",\n",
        "    \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"81\", \"82\",\n",
        "    \"83\", \"84\", \"85\", \"86\", \"88\", \"89\", \"90\", \"92\", \"93\",\n",
        "    \"94\", \"95\", \"97\", \"98\", \"99\"\n",
        "}\n",
        "\n",
        "def is_valid_plate(plate: str) -> bool:\n",
        "    return bool(VALID_PLATE_REGEX.match(plate))\n",
        "\n",
        "def is_valid_province(plate: str) -> bool:\n",
        "    match = re.match(r\"^(\\d{2})\", plate)\n",
        "    return bool(match and (match.group(1) in VALID_PROVINCES or plate.startswith(\"T\")))\n",
        "\n",
        "def is_valid_vietnam_plate(plate: str) -> bool:\n",
        "    if not is_valid_plate(plate):\n",
        "        return False\n",
        "    return is_valid_province(plate)\n",
        "\n",
        "# ====== CONFIG ======\n",
        "YOLO_PATH = \"/content/drive/MyDrive/ƒëoÃÇÃÄ aÃÅn 2/best.pt\"\n",
        "FRAME_STEP = 200  # ms default\n",
        "CONFIDENCE_THRESHOLD = 0.25  # default\n",
        "USE_EASYOCR_FALLBACK = True\n",
        "IOU_TH = 0.3  # Gi·∫£m t·ª´ 0.6 ƒë·ªÉ tr√°nh t√°ch track\n",
        "MAX_AGE = 50  # default\n",
        "\n",
        "# Sidebar v·ªõi b·ªë c·ª•c g·ªçn g√†ng\n",
        "st.sidebar.title(\"C√†i ƒë·∫∑t ·ª©ng d·ª•ng\")\n",
        "\n",
        "# Ph·∫ßn nh·∫≠p API Key\n",
        "st.sidebar.header(\"üîë Nh·∫≠p API Key\")\n",
        "GEMINI_API_KEY = st.sidebar.text_input(\"Nh·∫≠p Gemini API Key:\", type=\"password\")\n",
        "\n",
        "# Ph·∫ßn ch·ªçn phi√™n b·∫£n Gemini\n",
        "st.sidebar.header(\"üåê Ch·ªçn phi√™n b·∫£n Gemini\")\n",
        "GEMINI_MODEL_OPTIONS = {\n",
        "    \"gemini-1.5-flash\": \"~50 requests/ng√†y\",\n",
        "    \"gemini-1.5-pro\": \"~15 requests/ng√†y\",\n",
        "    \"gemini-2.0-flash\": \"~1000 requests/ng√†y\",\n",
        "    \"gemini-2.5-flash\": \"~1500 requests/ng√†y\",\n",
        "    \"gemini-2.5-pro\": \"~50-100 requests/ng√†y\"\n",
        "}\n",
        "selected_gemini_model = st.sidebar.selectbox(\n",
        "    \"Ch·ªçn m√¥ h√¨nh Gemini:\",\n",
        "    options=list(GEMINI_MODEL_OPTIONS.keys()),\n",
        "    index=list(GEMINI_MODEL_OPTIONS.keys()).index(\"gemini-2.5-flash\")  # Default l√† gemini-2.5-flash\n",
        ")\n",
        "st.sidebar.write(f\"Quota: {GEMINI_MODEL_OPTIONS[selected_gemini_model]}\")\n",
        "\n",
        "# Ph·∫ßn c√†i ƒë·∫∑t tham s·ªë ƒë·ªông\n",
        "st.sidebar.header(\"‚öôÔ∏è C√†i ƒë·∫∑t tham s·ªë\")\n",
        "CONFIDENCE_THRESHOLD = st.sidebar.slider(\"Ng∆∞·ª°ng tin c·∫≠y YOLO\", 0.1, 0.9, CONFIDENCE_THRESHOLD)\n",
        "FRAME_STEP = st.sidebar.slider(\"Kho·∫£ng c√°ch detect (ms)\", 100, 500, FRAME_STEP)\n",
        "MAX_AGE = st.sidebar.slider(\"Max age SORT\", 10, 100, MAX_AGE)\n",
        "IOU_TH = st.sidebar.slider(\"IoU threshold SORT\", 0.1, 0.8, IOU_TH)\n",
        "\n",
        "# C·∫•u h√¨nh Gemini d·ª±a tr√™n l·ª±a ch·ªçn\n",
        "if GEMINI_API_KEY:\n",
        "    import google.generativeai as genai\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    gemini_model = genai.GenerativeModel(selected_gemini_model)\n",
        "else:\n",
        "    gemini_model = None\n",
        "\n",
        "# ====== LOAD YOLO MODEL ======\n",
        "@st.cache_resource\n",
        "def load_yolo(path):\n",
        "    model = YOLO(path)\n",
        "    return model\n",
        "model = load_yolo(YOLO_PATH)\n",
        "\n",
        "# ====== REGEX CHU·∫®N H√ìA ======\n",
        "FALLBACK_REGEX = re.compile(r\"(\\d{2})\\s*[- ]?\\s*([A-Z]{1,2})\\s*[- ]?\\s*([0-9]{2,6})\")\n",
        "def normalize_plate(text: str) -> str:\n",
        "    text = text.upper()\n",
        "    text = re.sub(r\"[^A-Z0-9]\", \"\", text)\n",
        "    match = re.match(r\"^(\\d{2})([A-Z]{1,2})(\\d{2,6})$\", text)\n",
        "    if match:\n",
        "        p1, p2, p3 = match.groups()\n",
        "        return f\"{p1}-{p2} {p3}\"\n",
        "    match2 = FALLBACK_REGEX.search(text)\n",
        "    if match2:\n",
        "        p1, p2, p3 = match2.groups()\n",
        "        return f\"{p1}-{p2} {p3}\"\n",
        "    return text\n",
        "\n",
        "# ====== OCR ======\n",
        "def ocr_with_gemini(image: Image.Image) -> str:\n",
        "    try:\n",
        "        prompt = \"ƒê·ªçc bi·ªÉn s·ªë xe trong ·∫£nh (ch·ªâ tr·∫£ l·ªùi bi·ªÉn s·ªë, kh√¥ng th√™m k√Ω t·ª± n√†o kh√°c):\"\n",
        "        res = gemini_model.generate_content([prompt, image])\n",
        "        txt = res.text.strip()\n",
        "        return normalize_plate(txt)\n",
        "    except Exception as e:\n",
        "        st.warning(f\"L·ªói Gemini: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "@st.cache_resource\n",
        "def load_easyocr():\n",
        "    return easyocr.Reader(['en'])\n",
        "\n",
        "def ocr_with_easyocr(image: np.ndarray) -> str:\n",
        "    reader = load_easyocr()\n",
        "    results = reader.readtext(image)\n",
        "    txt = \" \".join([r[1] for r in results])\n",
        "    return normalize_plate(txt)\n",
        "\n",
        "# ====== TI·ªÄN X·ª¨ L√ù ROI ======\n",
        "def enhance_roi(roi: np.ndarray) -> np.ndarray:\n",
        "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(gray)\n",
        "    sharp = cv2.addWeighted(clahe, 1.5, cv2.GaussianBlur(clahe, (0,0), 1), -0.5, 0)\n",
        "    return cv2.cvtColor(sharp, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# ====== H√ÄM MERGE TRACKS ======\n",
        "def merge_tracks(tracks):\n",
        "    track_ids = sorted(tracks.keys())  # Sort ƒë·ªÉ merge theo th·ª© t·ª± tid\n",
        "    i = 0\n",
        "    while i < len(track_ids):\n",
        "        tid_i = track_ids[i]\n",
        "        if tid_i not in tracks:\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        j = i + 1\n",
        "        while j < len(track_ids):\n",
        "            tid_j = track_ids[j]\n",
        "            if tid_j not in tracks:\n",
        "                j += 1\n",
        "                continue\n",
        "\n",
        "            # Check IoU gi·ªØa bbox cu·ªëi i v√† bbox ƒë·∫ßu j\n",
        "            if tracks[tid_i][\"boxes_history\"] and tracks[tid_j][\"boxes_history\"]:\n",
        "                last_box_i = tracks[tid_i][\"boxes_history\"][-1]\n",
        "                first_box_j = tracks[tid_j][\"boxes_history\"][0]\n",
        "                if iou(last_box_i, first_box_j) > 0.5:  # Threshold merge\n",
        "                    # Merge j v√†o i\n",
        "                    tracks[tid_i][\"boxes_history\"].extend(tracks[tid_j][\"boxes_history\"])\n",
        "                    if tracks[tid_j][\"best_score\"] > tracks[tid_i][\"best_score\"]:\n",
        "                        tracks[tid_i][\"best_roi\"] = tracks[tid_j][\"best_roi\"]\n",
        "                        tracks[tid_i][\"best_score\"] = tracks[tid_j][\"best_score\"]\n",
        "                    del tracks[tid_j]\n",
        "                    track_ids.remove(tid_j)  # C·∫≠p nh·∫≠t list\n",
        "                else:\n",
        "                    j += 1\n",
        "        i += 1\n",
        "    return tracks\n",
        "\n",
        "# ====== HI·ªÇN TH·ªä GIAO DI·ªÜN ======\n",
        "st.title(\"Nh·∫≠n di·ªán bi·ªÉn s·ªë xe t·ª´ ·∫£nh ho·∫∑c video\")\n",
        "st.markdown(\"<div style='text-align:center; font-size:18px; color:gray;'>ƒê·ªì √°n II ‚Äì GVHD: ThS. Nguy·ªÖn Th·ªã Hu·∫ø</div>\", unsafe_allow_html=True)\n",
        "\n",
        "input_type = st.radio(\"Ch·ªçn lo·∫°i d·ªØ li·ªáu:\", [\"·∫¢nh\", \"Video\"])\n",
        "\n",
        "if input_type == \"·∫¢nh\":\n",
        "    uploaded_file = st.file_uploader(\"üì§ T·∫£i l√™n ·∫£nh\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "else:\n",
        "    uploaded_file = st.file_uploader(\"üì§ T·∫£i l√™n video\", type=[\"mp4\", \"mov\", \"avi\"])\n",
        "\n",
        "if uploaded_file and st.button(\"üöÄ B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán\"):\n",
        "    plate_counter = Counter()\n",
        "\n",
        "    # ================= X·ª¨ L√ù ·∫¢NH =================\n",
        "    if input_type == \"·∫¢nh\":\n",
        "        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
        "        image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
        "        result = model.predict(image, conf=CONFIDENCE_THRESHOLD, half=torch.cuda.is_available())[0]  # Th√™m half n·∫øu GPU\n",
        "        annotated = image.copy()\n",
        "\n",
        "        if len(result.boxes) == 0:\n",
        "            st.warning(\"‚ùå Kh√¥ng c√≥ bi·ªÉn s·ªë ƒë∆∞·ª£c ph√°t hi·ªán.\")\n",
        "        else:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                roi = annotated[y1:y2, x1:x2]\n",
        "                roi = enhance_roi(roi)\n",
        "\n",
        "                if gemini_model:\n",
        "                    pil_roi = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
        "                    txt_gem = ocr_with_gemini(pil_roi)\n",
        "                    txt_easy = ocr_with_easyocr(roi)\n",
        "                    # Ch·ªçn c√°i kh·ªõp regex t·ªët h∆°n\n",
        "                    if re.match(r\"^\\d{2}-[A-Z]{1,2} \\d{2,6}$\", txt_gem):\n",
        "                        text = txt_gem\n",
        "                    else:\n",
        "                        text = txt_easy\n",
        "                else:\n",
        "                    text = ocr_with_easyocr(roi) if USE_EASYOCR_FALLBACK else \"\"\n",
        "\n",
        "                if is_valid_vietnam_plate(text):\n",
        "                    plate_counter[text] += 1\n",
        "                else:\n",
        "                    st.info(f\"üö´ B·ªè qua chu·ªói kh√¥ng h·ª£p l·ªá: {text}\")\n",
        "                cv2.rectangle(annotated, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "                cv2.putText(annotated, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
        "\n",
        "            st.image(annotated, caption=\"·∫¢nh ƒë√£ nh·∫≠n di·ªán\", channels=\"BGR\", use_column_width=True)\n",
        "\n",
        "    # ================= X·ª¨ L√ù VIDEO =================\n",
        "    else:\n",
        "        # L∆∞u file t·∫°m\n",
        "        temp_video = tempfile.NamedTemporaryFile(delete=False)\n",
        "        temp_video.write(uploaded_file.read())\n",
        "        temp_video_path = temp_video.name\n",
        "\n",
        "        cap = cv2.VideoCapture(temp_video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        frame_interval = int(fps * FRAME_STEP / 1000) if FRAME_STEP > 0 else 1\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        out_path = \"output_annotated.mp4\"\n",
        "        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
        "\n",
        "        frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        pbar = st.progress(0.0)\n",
        "        ocr_status = st.empty()\n",
        "\n",
        "        # ================= PASS 1: TRACK + L·∫§Y ROI =================\n",
        "        sort_tracker = Sort(max_age=MAX_AGE, min_hits=1, iou_threshold=IOU_TH)\n",
        "        tracks = {}  # tid -> {\"best_roi\": np.array, \"best_score\": float, \"text\": str, \"boxes_history\": list}\n",
        "        box_found = False\n",
        "        idx = 0\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # YOLO detect theo frame_interval\n",
        "            if idx % frame_interval == 0:\n",
        "                result = model.predict(frame, conf=CONFIDENCE_THRESHOLD, verbose=False, half=torch.cuda.is_available())[0]\n",
        "                dets = np.array([\n",
        "                    [*box.xyxy[0].cpu().numpy(), box.conf[0].cpu().numpy()]\n",
        "                    for box in result.boxes\n",
        "                ]) if len(result.boxes) > 0 else np.empty((0, 5))\n",
        "\n",
        "                if len(dets) > 0:\n",
        "                    box_found = True\n",
        "            else:\n",
        "                dets = np.empty((0, 5))\n",
        "\n",
        "            # SORT update\n",
        "            trackers = sort_tracker.update(dets)\n",
        "\n",
        "            for track in trackers:\n",
        "                x1, y1, x2, y2, tid = map(int, track)\n",
        "                if tid not in tracks:\n",
        "                    tracks[tid] = {\n",
        "                        \"best_roi\": None,\n",
        "                        \"best_score\": -1.0,\n",
        "                        \"text\": \"\",\n",
        "                        \"boxes_history\": []\n",
        "                    }\n",
        "\n",
        "                tracks[tid][\"boxes_history\"].append([x1, y1, x2, y2])\n",
        "                if len(tracks[tid][\"boxes_history\"]) > 15:  # TƒÉng t·ª´ 7 l√™n 15\n",
        "                    tracks[tid][\"boxes_history\"].pop(0)\n",
        "\n",
        "                # Lu√¥n crop ROI t·ª´ SORT box\n",
        "                roi = frame[y1:y2, x1:x2]\n",
        "                if roi.size == 0:\n",
        "                    continue\n",
        "\n",
        "                # N·∫øu YOLO b·ªè s√≥t, confirm ROI b·∫±ng YOLO ph·ª• v·ªõi margin\n",
        "                matched = any(iou([x1, y1, x2, y2], det[:4]) > IOU_TH for det in dets)\n",
        "                if not matched:\n",
        "                    margin = 20  # pixel m·ªü r·ªông\n",
        "                    exp_y1, exp_y2 = max(0, y1 - margin), min(height, y2 + margin)\n",
        "                    exp_x1, exp_x2 = max(0, x1 - margin), min(width, x2 + margin)\n",
        "                    exp_roi = frame[exp_y1:exp_y2, exp_x1:exp_x2]\n",
        "                    sub_result = model.predict(exp_roi, conf=CONFIDENCE_THRESHOLD, verbose=False, half=torch.cuda.is_available())[0]\n",
        "                    if len(sub_result.boxes) == 0:\n",
        "                        continue  # ROI kh√¥ng ch·∫Øc ch·∫Øn l√† bi·ªÉn, b·ªè qua\n",
        "\n",
        "                # ƒê·∫øn ƒë√¢y ch·∫Øc ch·∫Øn ROI h·ª£p l·ªá, ki·ªÉm tra s·∫Øc n√©t\n",
        "                roi = enhance_roi(roi)\n",
        "                sc = sharpness_score(roi)\n",
        "                if sc > tracks[tid][\"best_score\"]:\n",
        "                    tracks[tid][\"best_score\"] = sc\n",
        "                    tracks[tid][\"best_roi\"] = roi\n",
        "\n",
        "            idx += 1\n",
        "            pbar.progress(min(idx / max(frames, 1), 1.0))\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        # Merge tracks tr∆∞·ªõc OCR\n",
        "        tracks = merge_tracks(tracks)\n",
        "\n",
        "        # ================= OCR cho m·ªói track =================\n",
        "        unique_texts = []\n",
        "        for tid, t in tracks.items():\n",
        "            if t[\"best_roi\"] is not None:\n",
        "                try:\n",
        "                    if gemini_model:\n",
        "                        ocr_status.markdown(\"‚úÖ **ƒêang d√πng Gemini OCR**\", unsafe_allow_html=True)\n",
        "                        pil_roi = Image.fromarray(cv2.cvtColor(t[\"best_roi\"], cv2.COLOR_BGR2RGB))\n",
        "                        txt_gem = ocr_with_gemini(pil_roi)\n",
        "                        txt_easy = ocr_with_easyocr(t[\"best_roi\"])\n",
        "                        # Ch·ªçn c√°i kh·ªõp regex t·ªët h∆°n\n",
        "                        if re.match(r\"^\\d{2}-[A-Z]{1,2} \\d{2,6}$\", txt_gem):\n",
        "                            txt = txt_gem\n",
        "                        else:\n",
        "                            txt = txt_easy\n",
        "                        if not txt.strip():\n",
        "                            ocr_status.markdown(\"‚ö†Ô∏è **Gemini v∆∞·ª£t quota, chuy·ªÉn EasyOCR**\", unsafe_allow_html=True)\n",
        "                            txt = txt_easy\n",
        "                    else:\n",
        "                        ocr_status.markdown(\"‚ö†Ô∏è **Ch∆∞a c√≥ API key, d√πng EasyOCR**\", unsafe_allow_html=True)\n",
        "                        txt = ocr_with_easyocr(t[\"best_roi\"])\n",
        "                    t[\"text\"] = txt.strip()\n",
        "                except Exception as e:\n",
        "                    ocr_status.markdown(f\"‚ö†Ô∏è **Gemini l·ªói ({e}), d√πng EasyOCR**\", unsafe_allow_html=True)\n",
        "                    t[\"text\"] = ocr_with_easyocr(t[\"best_roi\"])\n",
        "\n",
        "                if t[\"text\"] and is_valid_vietnam_plate(t[\"text\"]):\n",
        "                    unique_texts.append(t[\"text\"])\n",
        "                else:\n",
        "                    st.info(f\"üö´ B·ªè qua chu·ªói kh√¥ng h·ª£p l·ªá: {t['text']}\")\n",
        "\n",
        "        # ================= PASS 2: GHI VIDEO + DEBUG =================\n",
        "        cap = cv2.VideoCapture(temp_video_path)\n",
        "        sort_tracker = Sort(max_age=MAX_AGE, min_hits=1, iou_threshold=IOU_TH)\n",
        "        idx = 0\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if idx % frame_interval == 0:\n",
        "                result = model.predict(frame, conf=CONFIDENCE_THRESHOLD, half=torch.cuda.is_available())[0]\n",
        "                dets = np.array([[*box.xyxy[0].cpu().numpy(), box.conf[0].cpu().numpy()] for box in result.boxes]) if len(result.boxes) > 0 else np.empty((0, 5))\n",
        "            else:\n",
        "                dets = np.empty((0, 5))\n",
        "\n",
        "            trackers = sort_tracker.update(dets)\n",
        "\n",
        "            for track in trackers:\n",
        "                x1, y1, x2, y2, tid = map(int, track)\n",
        "                # Match tid v·ªõi tracks t·ª´ pass 1 b·∫±ng IoU\n",
        "                best_tid, best_iou = None, 0.0\n",
        "                for saved_tid, t in tracks.items():\n",
        "                    if t[\"boxes_history\"]:\n",
        "                        boxes_np = np.array(t[\"boxes_history\"])\n",
        "                        last_box = np.mean(boxes_np, axis=0).astype(int)\n",
        "                        ov = iou([x1, y1, x2, y2], last_box)\n",
        "                        if ov > IOU_TH and ov > best_iou:\n",
        "                            best_tid, best_iou = saved_tid, ov\n",
        "\n",
        "                if best_tid is not None:\n",
        "                    label = tracks[best_tid][\"text\"]\n",
        "                    if tracks[best_tid][\"boxes_history\"]:\n",
        "                        boxes_np = np.array(tracks[best_tid][\"boxes_history\"])\n",
        "                        x1, y1, x2, y2 = np.mean(boxes_np, axis=0).astype(int)\n",
        "                    # Debug hi·ªÉn th·ªã track + bi·ªÉn s·ªë\n",
        "                    cv2.putText(frame, f\"#{best_tid}\", (x1, y2 + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,0,0), 2)\n",
        "                else:\n",
        "                    label = \"\"\n",
        "\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                if label:\n",
        "                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "            out.write(frame)\n",
        "            idx += 1\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        # ================= HI·ªÇN TH·ªä K·∫æT QU·∫¢ =================\n",
        "        if not box_found:\n",
        "            st.warning(\"‚ùå Kh√¥ng c√≥ bi·ªÉn s·ªë ƒë∆∞·ª£c ph√°t hi·ªán trong video.\")\n",
        "        else:\n",
        "            st.subheader(\"üì• Video g·ªëc\")\n",
        "            col1, col2, col3 = st.columns([1, 2, 1])\n",
        "            with col2:\n",
        "                st.video(temp_video_path)\n",
        "\n",
        "            st.subheader(\"üñºÔ∏è ROI t·ªët nh·∫•t m·ªói track\")\n",
        "            for tid, t in tracks.items():\n",
        "                if t[\"best_roi\"] is not None and t[\"text\"] and is_valid_vietnam_plate(t[\"text\"]):\n",
        "                    st.image(\n",
        "                        t[\"best_roi\"],\n",
        "                        caption=f\"üñºÔ∏è Track #{tid} (Bi·ªÉn s·ªë: {t['text']})\",\n",
        "                        width=250\n",
        "                    )\n",
        "\n",
        "            st.subheader(\"üì• Video ƒë√£ nh·∫≠n di·ªán\")\n",
        "            with open(out_path, \"rb\") as f:\n",
        "                st.download_button(\n",
        "                    \"üì• T·∫£i video ƒë√£ nh·∫≠n di·ªán\",\n",
        "                    f,\n",
        "                    file_name=\"output_annotated.mp4\"\n",
        "                )\n",
        "\n",
        "        for txt in unique_texts:\n",
        "            plate_counter[txt] += 1\n",
        "\n",
        "    # ===== K·∫æT QU·∫¢ CU·ªêI =====\n",
        "    st.subheader(\"üìã Bi·ªÉn s·ªë ph√°t hi·ªán ƒë∆∞·ª£c:\")\n",
        "    found_plate = False\n",
        "    for plate, count in plate_counter.items():\n",
        "        if plate.strip():\n",
        "            st.write(f\"- **{plate}** ({count} l·∫ßn)\")\n",
        "            found_plate = True\n",
        "    if not found_plate:\n",
        "        st.warning(\"‚ùå Kh√¥ng c√≥ bi·ªÉn s·ªë ƒë∆∞·ª£c ph√°t hi·ªán.\")\n",
        "\n",
        "    # Export CSV\n",
        "    if plate_counter:\n",
        "        df = pd.DataFrame(list(plate_counter.items()), columns=['Bi·ªÉn s·ªë', 'S·ªë l·∫ßn'])\n",
        "        csv = df.to_csv(index=False).encode('utf-8')\n",
        "        st.download_button(\"üì• T·∫£i CSV k·∫øt qu·∫£\", csv, \"plates.csv\", \"text/csv\")\n",
        "\n",
        "# ===== GHI CH√ö =====\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "        <div style='position: fixed; bottom: 10px; right: 10px; font-size: 14px; color: gray;'>\n",
        "           By V√µ C√¥ng Nh·∫≠t - 20222627.\n",
        "        </div>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "# D·ªçn file t·∫°m (di chuy·ªÉn xu·ªëng ƒë√¢y ƒë·ªÉ sau download)\n",
        "try:\n",
        "    if 'temp_video' in locals() and os.path.exists(temp_video.name):\n",
        "        os.unlink(temp_video.name)\n",
        "    if 'out_path' in locals() and os.path.exists(out_path):\n",
        "        os.unlink(out_path)\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BBfmOYa5MpU3"
      },
      "outputs": [],
      "source": [
        "!streamlit run /content/project/app.py --server.port 8501 &> /content/log.txt &\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYHvpUgjMrkH",
        "outputId": "e1d7fa42-c3f4-408d-ffef-c09d2d301807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-08-26T02:53:09Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-08-26T02:53:09Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m |  https://titans-definitely-trainers-ot.trycloudflare.com                                   |\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.8.1 (Checksum a66353004197ee4c1fcb68549203824882bba62378ad4d00d234bdb8251f1114)\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 672cf60c-76bd-4f29-9f05-10d89856acfe\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "2025/08/26 02:53:12 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-08-26T02:53:12Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0maa61fabd-f01c-4d82-af96-257242c46bc1 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7 \u001b[36mlocation=\u001b[0mlax09 \u001b[36mprotocol=\u001b[0mquic\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared\n",
        "!./cloudflared tunnel --url http://localhost:8501\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPU6Xe71yUIVTTnUsbBRptt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}